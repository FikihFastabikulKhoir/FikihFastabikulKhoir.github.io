{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df0d91b4",
   "metadata": {},
   "source": [
    "# Import Library\n",
    "Library python adalah kumpulan modul terkait berisi kumpulan kode yang dapat digunakan berulang kali dalam program yang berbeda. Adanya library membuat pemrograman python menjadi lebih sederhana dan nyaman bagi programmer karena tidak perlu menulis kode yang sama berulang kali untuk program yang berbeda. maka dari itu terlebih dahulu kita perlu untuk melakukan import yang diperlukan, berikut ini import yang diperlukan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a372bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer, CountVectorizer\n",
    "import nltk \n",
    "import string\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d4932b",
   "metadata": {},
   "source": [
    "# Crawling Data\n",
    "Data Crawling adalah prosedur pengumpulan data besar yang dapat menjelajah hingga ke halaman web paling dalam. Library yang saya gunakan untuk melakukan crawling data adalah library scrapy. Untuk melakukan crawling data, yang diperlukan antara lain selector html dari data yang akan di crawling. code untuk crawling ini harus dijalankan pada terminal dengan cara mengetikkan \"scrapy namafile.py -o namafile.csv\". Berikut ini code untuk melakukan crawling data pada web pta.trunojoyo.ac.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf19d79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "\n",
    "class crawling(scrapy.Spider):\n",
    "    name = \"pta\"\n",
    "\n",
    "    def start_requests(self):\n",
    "        x = 100000\n",
    "        for i in range (1,200):\n",
    "            x += 1\n",
    "            urls = [\n",
    "                'https://pta.trunojoyo.ac.id/welcome/detail/040411' + str(x),\n",
    "                'https://pta.trunojoyo.ac.id/welcome/detail/070411' + str(x),\n",
    "                'https://pta.trunojoyo.ac.id/welcome/detail/080411' + str(x),\n",
    "            ]\n",
    "            for url in urls:\n",
    "                yield scrapy.Request(url=url, callback=self.parse)\n",
    "\n",
    "    def parse(self, response):\n",
    "        # print(response.url)\n",
    "        yield{\n",
    "            'judul': response.css('#content_journal > ul > li > div:nth-child(2) > a::text').extract(),\n",
    "            'abstraksi': response.css('#content_journal > ul > li > div:nth-child(4) > div:nth-child(2) > p::text').extract(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf46d990",
   "metadata": {},
   "source": [
    "# Membaca Data Crawling\n",
    "Agar data data yang sudah kita crawling tadi bisa terbaca dalam code, maka kita perlu untuk memanggil library pandas lalu memasukkan nama file hasil data crawling kita tadi. Berikut code yang diperlukan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "361e973f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>judul</th>\n",
       "      <th>abstraksi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pengembangan Sumber Daya Manusia Dalam Rangka ...</td>\n",
       "      <td>ABSTRAK\\r\\nPenelitian ini bertujuan untuk mene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PENGARUH ATRIBUT PRODUK TERHADAP KEPUTUSAN PEM...</td>\n",
       "      <td>Abstrak\\r\\n\\r\\nTujuan penelitian ini adalah un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               judul  \\\n",
       "0  Pengembangan Sumber Daya Manusia Dalam Rangka ...   \n",
       "1                                                NaN   \n",
       "2  PENGARUH ATRIBUT PRODUK TERHADAP KEPUTUSAN PEM...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                           abstraksi  \n",
       "0  ABSTRAK\\r\\nPenelitian ini bertujuan untuk mene...  \n",
       "1                                                NaN  \n",
       "2  Abstrak\\r\\n\\r\\nTujuan penelitian ini adalah un...  \n",
       "3                                                NaN  \n",
       "4                                                NaN  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('crawling.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea208f39",
   "metadata": {},
   "source": [
    "# Menghapus Baris yang Kosong\n",
    "Pada data yang telah kita crawling, setelah di cek ternyata banyak terdapat baris yang kosong. Untuk itu perlu kita hapus baris-baris yang kosong tersebut. berikut ini code untuk menghapus baris yang kosong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c64d3a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>judul</th>\n",
       "      <th>abstraksi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pengembangan Sumber Daya Manusia Dalam Rangka ...</td>\n",
       "      <td>ABSTRAK\\r\\nPenelitian ini bertujuan untuk mene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PENGARUH ATRIBUT PRODUK TERHADAP KEPUTUSAN PEM...</td>\n",
       "      <td>Abstrak\\r\\n\\r\\nTujuan penelitian ini adalah un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PENGARUH IKLAN ONLINE MELALUI MEDIA FACEBOOK T...</td>\n",
       "      <td>Abstrak\\r\\n\\r\\nHening Ary Putra, Pengaruh Ikla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PENGARUH UNSUR - UNSUR KOMUNIKASI TERHADAP PRO...</td>\n",
       "      <td>ABSTRAK\\r\\n\\r\\n\\tPenelitian ini bertujuan untu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PENGARUH DEBT TO TOTAL ASSET RATIO DAN CURRENT...</td>\n",
       "      <td>Abstrak\\r\\n\\r\\nPendekatan penelitian yang digu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                judul  \\\n",
       "0   Pengembangan Sumber Daya Manusia Dalam Rangka ...   \n",
       "2   PENGARUH ATRIBUT PRODUK TERHADAP KEPUTUSAN PEM...   \n",
       "6   PENGARUH IKLAN ONLINE MELALUI MEDIA FACEBOOK T...   \n",
       "8   PENGARUH UNSUR - UNSUR KOMUNIKASI TERHADAP PRO...   \n",
       "11  PENGARUH DEBT TO TOTAL ASSET RATIO DAN CURRENT...   \n",
       "\n",
       "                                            abstraksi  \n",
       "0   ABSTRAK\\r\\nPenelitian ini bertujuan untuk mene...  \n",
       "2   Abstrak\\r\\n\\r\\nTujuan penelitian ini adalah un...  \n",
       "6   Abstrak\\r\\n\\r\\nHening Ary Putra, Pengaruh Ikla...  \n",
       "8   ABSTRAK\\r\\n\\r\\n\\tPenelitian ini bertujuan untu...  \n",
       "11  Abstrak\\r\\n\\r\\nPendekatan penelitian yang digu...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna(inplace=True)\n",
    "data.isnull().sum()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c456fe",
   "metadata": {},
   "source": [
    "# Menghapus Baris yang Tidak Diperlukan\n",
    "Dalam permasalahan kali ini, data yang diperlukan hanya data abstraksi saja sedangkan data judul tidak diperlukan. Untuk itu perlu kita hapus kolom judul. Berikut ini code untuk menghapus kolom judul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6aacd074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstraksi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABSTRAK\\r\\nPenelitian ini bertujuan untuk mene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abstrak\\r\\n\\r\\nTujuan penelitian ini adalah un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Abstrak\\r\\n\\r\\nHening Ary Putra, Pengaruh Ikla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ABSTRAK\\r\\n\\r\\n\\tPenelitian ini bertujuan untu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Abstrak\\r\\n\\r\\nPendekatan penelitian yang digu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            abstraksi\n",
       "0   ABSTRAK\\r\\nPenelitian ini bertujuan untuk mene...\n",
       "2   Abstrak\\r\\n\\r\\nTujuan penelitian ini adalah un...\n",
       "6   Abstrak\\r\\n\\r\\nHening Ary Putra, Pengaruh Ikla...\n",
       "8   ABSTRAK\\r\\n\\r\\n\\tPenelitian ini bertujuan untu...\n",
       "11  Abstrak\\r\\n\\r\\nPendekatan penelitian yang digu..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(['judul'],axis=1,inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c55f6a",
   "metadata": {},
   "source": [
    "# Case Folding, Tokenizing, Stopword, dan Stemming\n",
    "Case folding adalah metode untuk mengubah semua huruf dalam dokumen menjadi huruf kecil. Tokenizing adalah proses pemisahan teks menjadi potongan-potongan yang disebut sebagai token untuk kemudian di analisa. Filtering adalah tahap mengambil kata-kata penting dari hasil token dengan menggunakan algoritma stoplist (membuang kata kurang penting) atau wordlist (menyimpan kata penting). Stemming adalah proses menghilangkan infleksi kata ke bentuk dasarnya, namun bentuk dasar tersebut tidak berarti sama dengan akar kata (root word)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a83fee9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstraksi</th>\n",
       "      <th>abstraksi_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABSTRAK\\r\\nPenelitian ini bertujuan untuk mene...</td>\n",
       "      <td>[abstrak, teliti, tuju, teliti, didik, latih, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abstrak\\r\\n\\r\\nTujuan penelitian ini adalah un...</td>\n",
       "      <td>[abstrak, tuju, teliti, identifikasi, variabel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Abstrak\\r\\n\\r\\nHening Ary Putra, Pengaruh Ikla...</td>\n",
       "      <td>[abstrak, hening, ary, putra, pengaruh, iklan,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ABSTRAK\\r\\n\\r\\n\\tPenelitian ini bertujuan untu...</td>\n",
       "      <td>[abstrak, teliti, tuju, pengaruh, unsur, unsur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Abstrak\\r\\n\\r\\nPendekatan penelitian yang digu...</td>\n",
       "      <td>[abstrak, dekat, teliti, teliti, dekat, kuanti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            abstraksi  \\\n",
       "0   ABSTRAK\\r\\nPenelitian ini bertujuan untuk mene...   \n",
       "2   Abstrak\\r\\n\\r\\nTujuan penelitian ini adalah un...   \n",
       "6   Abstrak\\r\\n\\r\\nHening Ary Putra, Pengaruh Ikla...   \n",
       "8   ABSTRAK\\r\\n\\r\\n\\tPenelitian ini bertujuan untu...   \n",
       "11  Abstrak\\r\\n\\r\\nPendekatan penelitian yang digu...   \n",
       "\n",
       "                                      abstraksi_clean  \n",
       "0   [abstrak, teliti, tuju, teliti, didik, latih, ...  \n",
       "2   [abstrak, tuju, teliti, identifikasi, variabel...  \n",
       "6   [abstrak, hening, ary, putra, pengaruh, iklan,...  \n",
       "8   [abstrak, teliti, tuju, pengaruh, unsur, unsur...  \n",
       "11  [abstrak, dekat, teliti, teliti, dekat, kuanti...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import stopword\n",
    "from nltk.corpus import stopwords \n",
    "stopwords_indonesia = stopwords.words('indonesian')\n",
    " \n",
    "#import sastrawi\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "#tokenize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    " \n",
    "# Happy Emoticons\n",
    "emoticons_happy = set([\n",
    "    ':-)', ':)', ';)', ':o)', ':]', ':3', ':c)', ':>', '=]', '8)', '=)', ':}',\n",
    "    ':^)', ':-D', ':D', '8-D', '8D', 'x-D', 'xD', 'X-D', 'XD', '=-D', '=D',\n",
    "    '=-3', '=3', ':-))', \":'-)\", \":')\", ':*', ':^*', '>:P', ':-P', ':P', 'X-P',\n",
    "    'x-p', 'xp', 'XP', ':-p', ':p', '=p', ':-b', ':b', '>:)', '>;)', '>:-)',\n",
    "    '<3'\n",
    "    ])\n",
    " \n",
    "# Sad Emoticons\n",
    "emoticons_sad = set([\n",
    "    ':L', ':-/', '>:/', ':S', '>:[', ':@', ':-(', ':[', ':-||', '=L', ':<',\n",
    "    ':-[', ':-<', '=\\\\', '=/', '>:(', ':(', '>.<', \":'-(\", \":'(\", ':\\\\', ':-c',\n",
    "    ':c', ':{', '>:\\\\', ';('\n",
    "    ])\n",
    " \n",
    "# all emoticons (happy + sad)\n",
    "emoticons = emoticons_happy.union(emoticons_sad)\n",
    " \n",
    "def clean_tweets(tweet):\n",
    "    # remove stock market tickers like $GE\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    " \n",
    "    # remove old style retweet abstraksi \"RT\"\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    " \n",
    "    # remove hyperlinks\n",
    "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "    \n",
    "    # remove hashtags\n",
    "    # only removing the hash # sign from the word\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    \n",
    "    #remove coma\n",
    "    tweet = re.sub(r',','',tweet)\n",
    "    \n",
    "    #remove angka\n",
    "    tweet = re.sub('[0-9]+', '', tweet)\n",
    " \n",
    "    # tokenize tweets\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
    "    tweet_tokens = tokenizer.tokenize(tweet)\n",
    " \n",
    "    tweets_clean = []    \n",
    "    for word in tweet_tokens:\n",
    "        if (word not in stopwords_indonesia and # remove stopwords\n",
    "              word not in emoticons and # remove emoticons\n",
    "                word not in string.punctuation): # remove punctuation\n",
    "            #tweets_clean.append(word)\n",
    "            stem_word = stemmer.stem(word) # stemming word\n",
    "            tweets_clean.append(stem_word)\n",
    " \n",
    "    return tweets_clean\n",
    "data['abstraksi_clean'] = data['abstraksi'].apply(lambda x: clean_tweets(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76fa17b",
   "metadata": {},
   "source": [
    "# Remove Punctuation \n",
    "Setelah kita melakukan proses diatas sebelumnya, hasil yang diperoleh memberikan banyak tambahan tanda baca, untuk itu perlu kita hapus tanda baca tersebut. Remove Punctuation adalah proses dimana sistem akan menghilangkan tanda baca atau simbol yang ada dalam dataset. Berikut code yang dibutuhkan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6852e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstraksi</th>\n",
       "      <th>abstraksi_clean</th>\n",
       "      <th>abstraksi_akhir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABSTRAK\\r\\nPenelitian ini bertujuan untuk mene...</td>\n",
       "      <td>[abstrak, teliti, tuju, teliti, didik, latih, ...</td>\n",
       "      <td>abstrak teliti tuju teliti didik latih pengaru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abstrak\\r\\n\\r\\nTujuan penelitian ini adalah un...</td>\n",
       "      <td>[abstrak, tuju, teliti, identifikasi, variabel...</td>\n",
       "      <td>abstrak tuju teliti identifikasi variabel atri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Abstrak\\r\\n\\r\\nHening Ary Putra, Pengaruh Ikla...</td>\n",
       "      <td>[abstrak, hening, ary, putra, pengaruh, iklan,...</td>\n",
       "      <td>abstrak hening ary putra pengaruh iklan online...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ABSTRAK\\r\\n\\r\\n\\tPenelitian ini bertujuan untu...</td>\n",
       "      <td>[abstrak, teliti, tuju, pengaruh, unsur, unsur...</td>\n",
       "      <td>abstrak teliti tuju pengaruh unsur unsur komun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Abstrak\\r\\n\\r\\nPendekatan penelitian yang digu...</td>\n",
       "      <td>[abstrak, dekat, teliti, teliti, dekat, kuanti...</td>\n",
       "      <td>abstrak dekat teliti teliti dekat kuantitatif ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            abstraksi  \\\n",
       "0   ABSTRAK\\r\\nPenelitian ini bertujuan untuk mene...   \n",
       "2   Abstrak\\r\\n\\r\\nTujuan penelitian ini adalah un...   \n",
       "6   Abstrak\\r\\n\\r\\nHening Ary Putra, Pengaruh Ikla...   \n",
       "8   ABSTRAK\\r\\n\\r\\n\\tPenelitian ini bertujuan untu...   \n",
       "11  Abstrak\\r\\n\\r\\nPendekatan penelitian yang digu...   \n",
       "\n",
       "                                      abstraksi_clean  \\\n",
       "0   [abstrak, teliti, tuju, teliti, didik, latih, ...   \n",
       "2   [abstrak, tuju, teliti, identifikasi, variabel...   \n",
       "6   [abstrak, hening, ary, putra, pengaruh, iklan,...   \n",
       "8   [abstrak, teliti, tuju, pengaruh, unsur, unsur...   \n",
       "11  [abstrak, dekat, teliti, teliti, dekat, kuanti...   \n",
       "\n",
       "                                      abstraksi_akhir  \n",
       "0   abstrak teliti tuju teliti didik latih pengaru...  \n",
       "2   abstrak tuju teliti identifikasi variabel atri...  \n",
       "6   abstrak hening ary putra pengaruh iklan online...  \n",
       "8   abstrak teliti tuju pengaruh unsur unsur komun...  \n",
       "11  abstrak dekat teliti teliti dekat kuantitatif ...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_punct(abstraksi):\n",
    "    abstraksi  = \" \".join([char for char in abstraksi if char not in string.punctuation])\n",
    "    return abstraksi\n",
    "\n",
    "data['abstraksi_akhir'] = data['abstraksi_clean'].apply(lambda x: remove_punct(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02fb1e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstraksi_akhir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abstrak teliti tuju teliti didik latih pengaru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abstrak tuju teliti identifikasi variabel atri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>abstrak hening ary putra pengaruh iklan online...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>abstrak teliti tuju pengaruh unsur unsur komun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>abstrak dekat teliti teliti dekat kuantitatif ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      abstraksi_akhir\n",
       "0   abstrak teliti tuju teliti didik latih pengaru...\n",
       "2   abstrak tuju teliti identifikasi variabel atri...\n",
       "6   abstrak hening ary putra pengaruh iklan online...\n",
       "8   abstrak teliti tuju pengaruh unsur unsur komun...\n",
       "11  abstrak dekat teliti teliti dekat kuantitatif ..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(['abstraksi','abstraksi_clean'],axis=1,inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7fe53505",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('abstrak_akhir.csv',encoding='utf8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094a6155",
   "metadata": {},
   "source": [
    "# TF - IDF\n",
    "Term Frequency — Inverse Document Frequency (TF — IDF) adalah suatu metode algoritma yang berguna untuk menghitung bobot setiap kata yang umum digunakan. Metode ini juga terkenal efisien, mudah dan memiliki hasil yang akurat. Metode ini akan menghitung nilai Term Frequency (TF) dan Inverse Document Frequency (IDF) pada setiap token (kata) di setiap dokumen dalam korpus. Secara sederhana, metode TF-IDF digunakan untuk mengetahui berapa sering suatu kata muncul di dalam dokumen. berikut rumus untuk mencari TF\n",
    "\n",
    "$w_{t d}=\\left\\{\\begin{array}{cl}1+\\log _{10} \\mathrm{tf}_{\\iota d}, & \\text { if } \\mathrm{tf}_{L d}>0 \\\\ 0, & \\text { if } \\mathrm{tf}_{t d}=0\\end{array}\\right.$\n",
    "\n",
    "Sedangkan untuk menghitung nilai idf dapat menggunakan rumus sebagai berikut\n",
    "\n",
    "$\\mathrm{idf}_{j}=\\log _{10}\\left(N / \\mathrm{df}_{j}\\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "594d5ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary:  {'abstrak': 7, 'teliti': 1593, 'tuju': 1657, 'didik': 350, 'latih': 851, 'pengaruh': 1126, 'parsial': 1101, 'simultan': 1439, 'rangka': 1274, 'tingkat': 1632, 'produktivitas': 1218, 'karyawan': 713, 'meniliti': 958, 'variabel': 1707, 'dominan': 374, 'bukti': 232, 'hipotesis': 563, 'alat': 59, 'analisis': 80, 'regresi': 1293, 'linier': 877, 'ganda': 493, 'bantu': 169, 'spss': 1474, 'hasil': 546, 'uji': 1672, 'nilai': 1033, 'fhitung': 461, 'signifikan': 1429, 'pt': 1237, 'pos': 1184, 'indonesia': 611, 'persero': 1155, 'kantor': 705, 'cabang': 243, 'bangkal': 164, 'koefisien': 763, 'determinasi': 340, 'square': 1475, 'ubah': 1669, 'sebab': 1378, 'sisa': 1446, 'masuk': 938, 'model': 991, 'benar': 195, 'beta': 206, 'identifikasi': 581, 'atribut': 136, 'produk': 1215, 'putus': 1262, 'beli': 193, 'sedap': 1382, 'masako': 934, 'mana': 914, 'metode': 968, 'kuantitatif': 811, 'populasi': 1180, 'ibu': 578, 'camat': 247, 'robatal': 1333, 'sampang': 1352, 'konsumsi': 785, 'teknik': 1586, 'ambil': 73, 'sampel': 1353, 'accidental': 11, 'sampling': 1356, 'oleh': 1062, 'responden': 1311, 'merek': 965, 'kemas': 731, 'label': 833, 'layan': 854, 'lengkap': 861, 'independen': 600, 'dependen': 329, 'terima': 1611, 'individu': 606, 'bebas': 187, 'positif': 1185, 'simpul': 1438, 'ikat': 586, 'kunci': 819, 'hening': 556, 'ary': 117, 'putra': 1260, 'iklan': 588, 'online': 1066, 'media': 942, 'facebook': 443, 'pakai': 1088, 'studi': 1505, 'mahasiswa': 901, 'fakultas': 450, 'ekonomi': 408, 'bisnis': 215, 'universitas': 1686, 'trunojoyo': 1652, 'madura': 899, 'pemimbing': 1120, 'bambang': 161, 'setiyo': 1413, 'pambudi': 1091, 'mm': 985, 'suyono': 1534, 'sikap': 1432, 'daya': 317, 'frekuensi': 485, 'klik': 759, 'faktor': 449, 'sebar': 1379, 'kuesioner': 815, 'vairabel': 1702, 'kecuali': 723, 'unsur': 1687, 'komunikasi': 776, 'kirim': 755, 'pesan': 1158, 'komunikator': 777, 'komunikan': 775, 'umpan': 1678, 'produktifitas': 1217, 'kerja': 741, 'pegawai': 1115, 'negeri': 1029, 'sipil': 1445, 'dinas': 356, 'kian': 753, 'kabupaten': 694, 'proporsional': 1229, 'random': 1273, 'kumpul': 818, 'data': 315, 'bagi': 152, 'riset': 1326, 'pustaka': 1257, 'olah': 1061, 'perangkat': 1137, 'lunak': 893, 'versi': 1715, 'validitas': 1703, 'reabilitas': 1286, 'skala': 1451, 'likert': 870, 'ftabel': 488, 'signifikansi': 1430, 'terang': 1605, 'varibel': 1711, 'langsung': 846, 'kominkator': 766, 'sigifikan': 1427, 'peran': 1136, 'upaya': 1690, 'dekat': 326, 'usaha': 1693, 'farmasi': 454, 'daftar': 304, 'bursa': 237, 'efek': 399, 'tari': 1571, 'purpossive': 1253, 'analis': 78, 'statistical': 1488, 'program': 1225, 'for': 477, 'service': 1408, 'solution': 1461, 'duga': 385, 'debt': 321, 'total': 1643, 'asset': 123, 'ratio': 1281, 'current': 299, 'return': 1318, 'on': 1064, 'dasar': 314, 'dapat': 311, 'dar': 312, 'cr': 294, 'roa': 1332, 'ach': 13, 'choirul': 266, 'ramadan': 1270, 'baur': 181, 'promosi': 1226, 'kunjung': 820, 'wisatawan': 1738, 'pantai': 1097, 'lombang': 884, 'sumenep': 1520, 'bimbing': 213, 'dr': 380, 'ir': 653, 'nurita': 1048, 'andriani': 89, 'yustina': 1750, 'chrismardani': 267, 'si': 1419, 'guna': 526, 'lapang': 848, 'wawancara': 1727, 'konsumen': 784, 'deskriptif': 337, 'nyata': 1052, 'bentuk': 197, 'tabulasi': 1552, 'hubung': 572, 'linear': 873, 'non': 1038, 'probability': 1211, 'purposive': 1252, 'advertising': 27, 'sales': 1349, 'promotion': 1227, 'public': 1240, 'relation': 1296, 'and': 87, 'publicty': 1241, 'direct': 357, 'marketing': 930, 'hitung': 564, 'lebih': 857, 'jual': 686, 'humas': 576, 'publikasi': 1243, 'pasar': 1103, 'saing': 1345, 'dunia': 389, 'hadap': 529, 'tuntut': 1664, 'dietahui': 351, 'tantang': 1569, 'jalan': 668, 'bangun': 166, 'salah': 1348, 'langkah': 845, 'strategi': 1497, 'dukung': 387, 'stres': 1502, 'kondisi': 778, 'intrinsik': 645, 'kembang': 732, 'karir': 709, 'struktur': 1504, 'organisasi': 1073, 'petrocentral': 1162, 'gresik': 522, 'motivasi': 1000, 'tentu': 1601, 'sumber': 1518, 'informasi': 618, 'tebukti': 1579, 'elemen': 413, 'ekuitas': 411, 'sadar': 1343, 'brand': 226, 'awareness': 145, 'asosiasi': 121, 'assocations': 126, 'kesan': 744, 'kualitas': 808, 'perceived': 1139, 'quality': 1264, 'loyalitas': 886, 'loyalty': 887, 'handphone': 534, 'blackberry': 216, 'ukur': 1674, 'untuk': 1688, 'instrumen': 627, 'reliabilitas': 1300, 'asumsi': 129, 'klasik': 758, 'sedang': 1381, 'naik': 1023, 'harga': 539, 'minta': 977, 'saham': 1344, 'alami': 58, 'turun': 1666, 'fluk': 474, 'tuatif': 1655, 'hindar': 561, 'kisar': 756, 'tarik': 1573, 'minat': 972, 'investor': 652, 'pecah': 1112, 'stock': 1494, 'split': 1472, 'masalah': 935, 'beda': 188, 'bei': 190, 'paired': 1087, 'sample': 1354, 'test': 1613, 'periode': 1147, 'amat': 71, 'penetuan': 1125, 'rata': 1280, 'tva': 1667, 'volume': 1718, 'dagang': 305, 'gera': 504, 'kompensasi': 768, 'finansial': 464, 'nonfinansial': 1039, 'milik': 971, 'andy': 90, 'saputro': 1363, 'distribusi': 364, 'kripik': 804, 'singkong': 1443, 'muris': 1017, 'industri': 615, 'rumah': 1339, 'tangga': 1565, 'saronggi': 1367, 'pribanus': 1205, 'wantara': 1722, 'drs': 384, 'had': 528, 'purnomo': 1251, 'mengetauhi': 954, 'jenis': 681, 'kuisioner': 816, 'observasi': 1056, 'insidental': 623, 'anugerah': 101, 'dwi': 390, 'nanda': 1024, 'puas': 1238, 'bojonegoroputera': 222, 'contractor': 289, 'general': 501, 'supplier': 1524, 'bojonegoro': 221, 'bawah': 183, 'anugrahini': 102, 'irawati': 655, 'helm': 552, 'buyung': 241, 'aulia': 140, 'balas': 159, 'jasa': 676, 'adil': 22, 'layak': 853, 'capai': 250, 'prestasi': 1203, 'rangsang': 1275, 'aktif': 46, 'liput': 878, 'putera': 1259, 'kompesasi': 769, 'muncul': 1016, 'lahir': 835, 'budaya': 229, 'emis': 414, 'anak': 77, 'pilih': 1164, 'profesi': 1220, 'lingkung': 875, 'keluarga': 730, 'peria': 1143, 'biasa': 207, 'hidup': 559, 'hari': 541, 'perilaku': 1144, 'kamal': 700, 'kab': 693, 'prihatin': 1207, 'indikator': 605, 'etnografis': 433, 'persepsi': 1154, 'sosialisasi': 1465, 'modus': 994, 'operandi': 1067, 'praktek': 1193, 'jaring': 675, 'desa': 331, 'variable': 1709, 'indicator': 602, 'behavioral': 189, 'sociology': 1458, 'tingkah': 1631, 'laku': 839, 'akibat': 41, 'teory': 1603, 'exchange': 439, 'of': 1059, 'social': 1457, 'kecewa': 722, 'manusia': 921, 'adnya': 25, 'dorong': 376, 'sosial': 1464, 'anissa': 97, 'novianti': 1042, 'minyak': 979, 'goreng': 520, 'sania': 1360, 'graha': 521, 'permai': 1151, 'simple': 1437, 'ulfiyatun': 1676, 'mutohharoh': 1021, 'preferensi': 1201, 'belanja': 192, 'fashion': 455, 'mahasiwa': 903, 'journal': 685, 'economics': 398, 'manajemen': 915, 'mohamad': 996, 'tambrin': 1559, 'crismardani': 296, 'internet': 639, 'sistem': 1447, 'global': 515, 'bas': 175, 'komputer': 774, 'perlahan': 1150, 'lahan': 834, 'geser': 507, 'konvensional': 789, 'praktis': 1195, 'modern': 993, 'rilis': 1322, 'detik': 341, 'com': 282, 'timbang': 1625, 'menetukan': 951, 'gantung': 495, 'interdependent': 632, 'statistic': 1487, 'konfirmatori': 780, 'kmo': 760, 'item': 662, 'rendah': 1302, 'klasifikasi': 757, 'miserable': 981, 'statistik': 1489, 'kecukuperatan': 724, 'alternatif': 67, 'image': 592, 'mampu': 912, 'citra': 276, 'penlitian': 1132, 'es': 431, 'krim': 803, 'wall': 1720, 'purchasing': 1249, 'decisions': 324, 'hardik': 538, 'pratama': 1199, 'makan': 906, 'tradisional': 1646, 'muh': 1012, 'syarif': 1546, 'ec': 395, 'pribadi': 1204, 'psikologis': 1236, 'keputsan': 739, 'kuci': 814, 'erilaku': 429, 'deskripsi': 336, 'inovasi': 622, 'unggul': 1682, 'terap': 1606, 'optik': 1068, 'reza': 1320, 'lamongan': 841, 'kualitatif': 809, 'fenomenologi': 460, 'dokumen': 372, 'reduction': 1290, 'display': 361, 'conclusion': 284, 'drawing': 382, 'verification': 1714, 'omzet': 1063, 'tawar': 1576, 'baik': 157, 'pangsa': 1096, 'luas': 890, 'daerah': 303, 'jawa': 677, 'timur': 1628, 'teh': 1581, 'pucuk': 1245, 'harum': 544, 'jamin': 671, 'garansi': 497, 'negatif': 1028, 'rasa': 1276, 'ah': 34, 'faqih': 452, 'qoriwildani': 1263, 'langgan': 844, 'speedy': 1469, 'telekomunikasi': 1590, 'tbk': 1577, 'kota': 796, 'pamekasan': 1093, 'nirma': 1034, 'kurriwati': 824, 'sp': 1468, 'ratus': 1283, 'persen': 1152, 'telkom': 1594, 'muas': 1008, 'satu': 1372, 'besar': 205, 'tanggap': 1566, 'empati': 418, 'fisik': 468, 'jadi': 666, 'orang': 1072, 'anggap': 91, 'tele': 1589, 'pame': 1092, 'kasan': 716, 'reni': 1303, 'anggraini': 93, 'prodi': 1213, 'strata': 1496, 'akuntansi': 53, 'forensik': 478, 'fathor': 456, 'as': 118, 'personal': 1156, 'selling': 1396, 'publisitas': 1244, 'jenuh': 682, 'dokumentasi': 373, 'ulang': 1675, 'nasabah': 1025, 'bri': 227, 'banking': 168, 'manfaat': 919, 'mudah': 1010, 'aman': 69, 'sedia': 1384, 'fitur': 470, 'maju': 905, 'lihat': 869, 'pesat': 1160, 'fenomena': 459, 'tahan': 1554, 'hargapromosi': 540, 'khusus': 752, 'bahas': 154, 'toko': 1638, 'fely': 458, 'jaya': 678, 'lg': 867, 'kacamatan': 695, 'analisa': 79, 'elektronik': 412, 'saran': 1364, 'buka': 231, 'letak': 864, 'strategis': 1498, 'nyaman': 1051, 'rumus': 1342, 'lapor': 849, 'biaya': 208, 'minimal': 976, 'risiko': 1327, 'cacat': 244, 'cv': 302, 'kapuas': 706, 'inti': 642, 'sarana': 1365, 'profitabilitas': 1224, 'gambar': 492, 'asal': 119, 'periodik': 1148, 'perinci': 1145, 'kurang': 822, 'butuh': 240, 'wujud': 1744, 'visi': 1717, 'misi': 982, 'sesuai': 1411, 'tetap': 1614, 'anggota': 92, 'laksana': 838, 'optimal': 1069, 'kait': 696, 'kefektifan': 725, 'salur': 1350, 'atas': 132, 'horizontal': 569, 'kali': 698, 'primer': 1209, 'kuisoner': 817, 'starfood': 1483, 'international': 638, 'paciran': 1083, 'clustered': 278, 'secaa': 1380, 'keywords': 748, 'devi': 342, 'kamalia': 701, 'mix': 984, 'sentra': 1403, 'mutira': 1020, 'batik': 178, 'lokasi': 883, 'mutiara': 1019, 'survey': 1530, 'realibilitas': 1288, 'men': 948, 'guji': 525, 'varabel': 1705, 'adjusted': 24, 'squere': 1476, 'angka': 96, 'variasi': 1710, 'sama': 1351, 'luar': 889, 'empat': 417, 'masyarakat': 939, 'berdasrkan': 201, 'ike': 587, 'miranti': 980, 'maan': 896, 'ghodaqo': 510, 'siddiq': 1421, 'lestari': 863, 'jombang': 684, 'kurriwatispmsi': 825, 'menitikberatkan': 959, 'air': 36, 'mineral': 973, 'purprosive': 1254, 'maret': 923, 'instrument': 628, 'teknis': 1587, 'memakaiuji': 945, 'software': 1459, 'samsuki': 1358, 'iklim': 589, 'bank': 167, 'hj': 565, 'iriani': 657, 'ismail': 660, 'dra': 381, 'faidal': 445, 'bumn': 234, 'uang': 1668, 'tekan': 1584, 'calon': 246, 'karyawannya': 714, 'lanjut': 847, 'tanggung': 1567, 'imbal': 594, 'hangat': 535, 'setia': 1412, 'simutan': 1441, 'equity': 426, 'firm': 467, 'size': 1450, 'leverage': 866, 'business': 239, 'risk': 1328, 'bijak': 212, 'deviden': 344, 'manufaktur': 920, 'businees': 238, 'dividend': 369, 'payout': 1110, 'muzanni': 1022, 'piutang': 1168, 'tertahadap': 1612, 'rentabilitas': 1304, 'koperasi': 790, 'syariah': 1545, 'bmt': 219, 'ugt': 1671, 'sidogiri': 1424, 'kpri': 799, 'kopergu': 791, 'evaliati': 435, 'amaniyah': 70, 'msm': 1006, 'purnamawati': 1250, 'lembaga': 859, 'pinjam': 1167, 'dana': 310, 'otomatis': 1075, 'modal': 990, 'tanam': 1562, 'potensi': 1188, 'untung': 1689, 'kelola': 728, 'rasio': 1278, 'aktivitas': 49, 'kriterian': 806, 'efisien': 406, 'tumbuh': 1659, 'putar': 1258, 'cepat': 258, 'kategori': 718, 'kurniawati': 823, 'earning': 392, 'share': 1417, 'net': 1030, 'profit': 1223, 'margin': 924, 'to': 1636, 'otomotif': 1076, 'komponen': 772, 'gatot': 498, 'heru': 557, 'prajoto': 1192, 'prasetyo': 1198, 'nugroho': 1046, 'pi': 1163, 'moh': 995, 'taufik': 1575, 'hatimah': 548, 'kec': 721, 'proppo': 1230, 'swot': 1540, 'kuat': 813, 'lemah': 858, 'peluang': 1119, 'ancam': 86, 'market': 929, 'provider': 1234, 'kartu': 712, 'seluler': 1397, 'tahun': 1556, 'ringan': 1324, 'formulasi': 482, 'agresif': 29, 'banding': 162, 'indra': 614, 'tegas': 1580, 'pimpin': 1165, 'apollo': 106, 'surabaya': 1527, 'muhammad': 1014, 'alkirom': 63, 'wildansemsi': 1735, 'leseh': 862, 'berkah': 203, 'ilaahi': 591, 'anti': 100, 'kontrak': 786, 'sapta': 1362, 'pusaka': 1255, 'nusantara': 1049, 'spgn': 1470, 'popuasi': 1179, 'arah': 110, 'hudan': 573, 'dardiri': 313, 'septiawan': 1405, 'casablanca': 254, 'pomade': 1176, 'rambut': 1272, 'tidak': 1620, 'proses': 1231, 'pomede': 1177, 'distibusi': 362, 'sholeh': 1418, 'televisi': 1592, 'xl': 1746, 'geger': 500, 'isi': 659, 'format': 481, 'bachrowi': 149, 'minum': 978, 'yoghurt': 1748, 'cimory': 270, 'cisarua': 275, 'mountain': 1002, 'dairy': 306, 'bogor': 220, 'masayarakat': 936, 'se': 1377, 'ssi': 1479, 'terdiridari': 1608, 'muazzah': 1009, 'judul': 688, 'overreaction': 1081, 'makhmud': 907, 'zulkifli': 1752, 'dosem': 377, 'msi': 1005, 'dosen': 378, 'decade': 322, 'investasi': 649, 'simpang': 1435, 'januari': 674, 'effect': 403, 'day': 316, 'the': 1616, 'week': 1728, 'overreactio': 1080, 'mengatahui': 953, 'reaksi': 1287, 'peristiwa': 1149, 'puasa': 1239, 'jelang': 679, 'lebaran': 856, 'in': 595, 'abnormal': 5, 'tanda': 1563, 'portofolio': 1183, 'loser': 885, 'winner': 1737, 'deduktif': 325, 'sistematis': 1448, 'aktual': 50, 'akurat': 55, 'fakta': 448, 'teori': 1602, 'pola': 1175, 'aar': 0, 'average': 144, 'car': 252, 'cumulative': 298, 'abnormar': 6, 'kelompok': 729, 'temu': 1598, 'menggungguli': 956, 'balik': 160, 'efektivitas': 402, 'awas': 146, 'intern': 635, 'manajerial': 916, 'puncak': 1247, 'tengah': 1600, 'windows': 1736, 'stratified': 1500, 'korelasi': 793, 'product': 1214, 'moment': 999, 'alpha': 65, 'cronbach': 297, 'one': 1065, 'tail': 1557, 'liner': 874, 'efektif': 400, 'endang': 420, 'hariyani': 542, 'switching': 1539, 'nokia': 1036, 'wilayah': 1732, 'telang': 1588, 'mohammad': 997, 'arief': 114, 'corporation': 291, 'produsen': 1219, 'finlandia': 465, 'produksi': 1216, 'protokol': 1232, 'utama': 1700, 'gsm': 523, 'cdma': 256, 'umts': 1679, 'berat': 199, 'samsung': 1359, 'apple': 107, 'zte': 1751, 'cina': 271, 'agam': 28, 'telepon': 1591, 'cipta': 272, 'dampak': 308, 'pindah': 1166, 'eksplorator': 410, 'tehnik': 1583, 'factor': 444, 'analysis': 84, 'bagus': 153, 'penasaran': 1121, 'segi': 1385, 'ayu': 148, 'massita': 937, 'efektifitas': 401, 'mandiri': 918, 'kuantitas': 810, 'sdm': 1376, 'harap': 537, 'sinifikan': 1444, 'benah': 194, 'lukman': 892, 'waqi': 1724, 'arianto': 113, 'go': 518, 'publik': 1242, 'mahkmud': 904, 'echsan': 397, 'gani': 494, 'kandung': 704, 'pasti': 1106, 'resiko': 1307, 'perhati': 1142, 'hendak': 554, 'kombinasi': 765, 'sekuritas': 1391, 'catat': 255, 'expected': 440, 'standart': 1482, 'deviasi': 343, 'trada': 1645, 'maritime': 928, 'potofolio': 1189, 'pleh': 1169, 'diversifikasi': 367, 'kusniyah': 826, 'spi': 1471, 'statis': 1486, 'fluktuatif': 475, 'likuiditas': 871, 'empiris': 419, 'aktifitas': 47, 'kehandalan': 726, 'rakyat': 1269, 'aju': 39, 'susun': 1533, 'menggunaka': 955, 'systematic': 1549, 'objek': 1053, 'debit': 320, 'britama': 228, 'man': 913, 'steel': 1491, 'tempat': 1596, 'tinggal': 1629, 'aspek': 122, 'percaya': 1138, 'hati': 547, 'customer': 300, 'satisfaction': 1369, 'hadiatullah': 530, 'rokok': 1336, 'interpretasi': 641, 'hanjaya': 536, 'mandala': 917, 'sampoerna': 1357, 'solvabilitas': 1462, 'gudang': 524, 'garam': 496, 'bentoel': 196, 'internasional': 637, 'investama': 648, 'lancar': 842, 'kas': 715, 'assets': 125, 'time': 1627, 'interest': 633, 'earned': 391, 'inventory': 647, 'turnover': 1665, 'fixed': 471, 'mild': 970, 'socah': 1456, 'meguji': 943, 'self': 1395, 'efficacy': 404, 'magnitude': 900, 'generality': 503, 'strength': 1501, 'akademik': 40, 'ikut': 590, 'mawapres': 940, 'teridiri': 1610, 'rasional': 1279, 'dividen': 368, 'kandidat': 703, 'cut': 301, 'off': 1060, 'point': 1173, 'excess': 438, 'returns': 1319, 'erb': 428, 'ci': 269, 'komposisi': 773, 'proporsi': 1228, 'adaro': 21, 'energy': 422, 'hm': 566, 'astra': 127, 'otopart': 1078, 'multi': 1015, 'bintang': 214, 'agro': 30, 'goodyear': 519, 'indika': 603, 'united': 1685, 'tractors': 1644, 'pabrik': 1082, 'kertas': 743, 'tjiwi': 1635, 'kimia': 754, 'indofood': 609, 'sukses': 1515, 'makmur': 908, 'negara': 1027, 'indeks': 599, 'tunggal': 1662, 'aktiva': 48, 'pns': 1171, 'lutfi': 895, 'botol': 224, 'sosro': 1466, 'study': 1506, 'prioritas': 1210, 'industry': 616, 'npm': 1044, 'investment': 651, 'roi': 1335, 'roe': 1334, 'eps': 425, 'dpr': 379, 'sial': 1420, 'retun': 1317, 'rekrutmen': 1294, 'terhdap': 1609, 'pusat': 1256, 'sejahtera': 1388, 'katakunci': 717, 'rekrutmenpengembangan': 1295, 'pandang': 1094, 'dealer': 318, 'surya': 1531, 'agung': 31, 'motor': 1001, 'resmi': 1308, 'honda': 568, 'gerak': 506, 'sepeda': 1404, 'kotler': 797, 'armstrong': 116, 'gaya': 499, 'desain': 332, 'supra': 1525, 'mempunyah': 947, 'cerdas': 259, 'emosional': 415, 'burneh': 236, 'tanah': 1561, 'merah': 963, 'galis': 491, 'blega': 217, 'memilki': 946, 'paham': 1086, 'suasana': 1507, 'intrapersonal': 644, 'interpersonal': 640, 'intention': 631, 'this': 1617, 'research': 1306, 'is': 658, 'know': 761, 'influence': 617, 'location': 882, 'effort': 405, 'decision': 323, 'also': 66, 'which': 1730, 'such': 1511, 'having': 550, 'bigger': 211, 'ppengaruh': 1190, 'at': 131, 'home': 567, 'eat': 393, 'depot': 330, 'soto': 1467, 'glorious': 516, 'asih': 120, 'use': 1694, 'quantitative': 1265, 'method': 967, 'with': 1741, 'approach': 108, 'population': 1181, 'entire': 424, 'all': 64, 'consumer': 287, 'doing': 371, 'conducting': 285, 'used': 1695, 'hence': 553, 'get': 508, 'responder': 1312, 'collecting': 280, 'into': 643, 'library': 868, 'result': 1314, 'mention': 961, 'tied': 1621, 'that': 1615, 'while': 1731, 'from': 487, 'prove': 1233, 'free': 484, 'consisting': 286, 'by': 242, 'or': 1071, 'together': 1637, 'can': 249, 'be': 185, 'concluded': 283, 'both': 223, 'have': 549, 'purchase': 1248, 'mini': 975, 'alfamart': 60, 'bauaran': 179, 'deterjen': 338, 'rinso': 1325, 'noda': 1035, 'domisili': 375, 'susu': 1532, 'cair': 245, 'indomilk': 610, 'swalayan': 1537, 'tom': 1640, 'jerry': 683, 'musthofa': 1018, 'tiket': 1622, 'kereta': 740, 'api': 104, 'stasiun': 1484, 'sidoarjo': 1423, 'wantaradrs': 1723, 'dan': 309, 'suyonose': 1535, 'ka': 692, 'sig': 1426, 'koefisen': 762, 'tinggi': 1630, 'keyword': 747, 'tiketkepuasan': 1623, 'id': 580, 'fitri': 469, 'anna': 98, 'sari': 1366, 'hotel': 570, 'madinah': 898, 'konsuman': 783, 'kara': 707, 'vario': 1713, 'uni': 1683, 'martabak': 933, 'hawaii': 551, 'landas': 843, 'filsafat': 462, 'positivisme': 1187, 'menejerial': 950, 'institusional': 625, 'kepamilikan': 736, 'yudhistira': 1749, 'west': 1729, 'key': 746, 'words': 1743, 'petis': 1161, 'ikan': 585, 'tuna': 1660, 'diya': 370, 'lurah': 894, 'banyuanyar': 171, 'kosumen': 795, 'ditribusi': 366, 'abstraksi': 8, 'pradityo': 1191, 'kusumajani': 827, 'kompetensi': 770, 'jabat': 665, 'listrik': 880, 'rm': 1331, 'mochammad': 989, 'wispandonos': 1740, 'mudji': 1011, 'kuswinarno': 830, 'pln': 1170, 'integritas': 630, 'inisiatif': 620, 'kontrol': 788, 'integrasi': 629, 'individual': 607, 'latar': 850, 'belakang': 191, 'ketat': 745, 'segmen': 1386, 'mobil': 987, 'mpv': 1003, 'suzuki': 1536, 'ertiga': 430, 'tinjau': 1633, 'penuh': 1134, 'indpenden': 613, 'value': 1704, 'tabung': 1553, 'emotional': 416, 'performance': 1140, 'price': 1206, 'flashdisk': 472, 'toshiba': 1642, 'utm': 1701, 'corporate': 290, 'user': 1696, 'rawat': 1284, 'inap': 596, 'banyak': 170, 'sakit': 1347, 'pokok': 1174, 'tarif': 1572, 'activity': 16, 'based': 176, 'costing': 293, 'system': 1548, 'abcs': 2, 'distorsi': 363, 'kalkulasi': 699, 'telusur': 1595, 'cermat': 261, 'skripsi': 1454, 'deskriftif': 335, 'lukis': 891, 'abc': 1, 'kelas': 727, 'vip': 1716, 'beban': 186, 'overhead': 1079, 'rinci': 1323, 'driver': 383, 'cost': 292, 'timbul': 1626, 'abtrak': 9, 'uswatun': 1699, 'khasanah': 750, 'etos': 434, 'presatasi': 1202, 'diatribusi': 349, 'area': 112, 'mojokerto': 998, 'mengunakan': 957, 'semanagt': 1399, 'disiplin': 359, 'semangat': 1400, 'retailing': 1316, 'merchandise': 964, 'atmosfer': 134, 'gerai': 505, 'retailimg': 1315, 'idola': 582, 'mart': 932, 'kwanyar': 831, 'malam': 911, 'collector': 281, 'kredit': 802, 'psikis': 1235, 'jumlah': 689, 'variebel': 1712, 'yamaha': 1747, 'new': 1031, 'jupiter': 690, 'liniear': 876, 'aplikasi': 105, 'ada': 18, 'dalam': 307, 'pegang': 1114, 'penting': 1133, 'tempuh': 1597, 'beri': 202, 'syarifah': 1547, 'ambami': 72, 'rato': 1282, 'ebu': 394, 'adalahu': 19, 'ntuk': 1045, 'tenaga': 1599, 'paramedis': 1100, 'ujivaliditasuji': 1673, 'asum': 128, 'siklasik': 1433, 'penjelasany': 1130, 'nya': 1050, 'taraf': 1570, 'badan': 150, 'bidang': 210, 'nasional': 1026, 'paktek': 1090, 'optimalisasi': 1070, 'sumbr': 1519, 'sifat': 1425, 'kenal': 733, 'orgnisasional': 1074, 'mentor': 962, 'sponsor': 1473, 'sempat': 1402, 'engembangan': 423, 'kerjakaryawan': 742, 'made': 897, 'ardi': 111, 'dharmawan': 347, 'isotonik': 661, 'pocari': 1172, 'sweat': 1538, 'tunjuk': 1663, 'marketix': 931, 'imam': 593, 'humaini': 574, 'pranjoto': 1197, 'bep': 198, 'kriteria': 805, 'terbit': 1607, 'delisting': 327, 'indonesian': 612, 'capital': 251, 'directori': 358, 'icmd': 579, 'level': 865, 'significance': 1428, 'tehadap': 1582, 'ecer': 396, 'barang': 172, 'indah': 598, 'evans': 437, 'foster': 483, 'bangakalan': 163, 'jamu': 672, 'tolak': 1639, 'angin': 95, 'sido': 1422, 'manyar': 922, 'satiyah': 1370, 'laut': 852, 'irawatimm': 656, 'auliasst': 141, 'sem': 1398, 'mt': 1007, 'instansi': 624, 'pengembnagan': 1127, 'terampil': 1604, 'tahu': 1555, 'kondusif': 779, 'menganalisa': 952, 'observasional': 1057, 'analitik': 83, 'probality': 1212, 'partisipasi': 1102, 'seleksi': 1393, 'serta': 1406, 'instruktur': 626, 'thitung': 1618, 'farid': 453, 'shampo': 1415, 'pantene': 1098, 'dungkek': 388, 'softwere': 1460, 'vareabel': 1706, 'shampoo': 1416, 'diskriptif': 360, 'maksud': 910, 'tani': 1568, 'analisisa': 81, 'reduksi': 1291, 'saji': 1346, 'urai': 1691, 'singkat': 1442, 'rumput': 1341, 'kandang': 702, 'tangan': 1564, 'bibit': 209, 'bluto': 218, 'bayar': 184, 'tunai': 1661, 'hambat': 532, 'jemur': 680, 'sehat': 1387, 'dimensi': 354, 'relationship': 1297, 'timbal': 1624, 'simultas': 1440, 'sembah': 1401, 'kopontren': 792, 'hendra': 555, 'irawan': 654, 'komitmen': 767, 'patner': 1108, 'adira': 23, 'dinamika': 355, 'finance': 463, 'kuswinanrno': 828, 'survai': 1528, 'quota': 1267, 'jalur': 670, 'path': 1107, 'nur': 1047, 'hidayat': 558, 'sasar': 1368, 'warga': 1726, 'umur': 1680, 'determinan': 339, 'bundling': 235, 'strategy': 1499, 'restoran': 1313, 'quick': 1266, 'chicken': 265, 'raya': 1285, 'dukuh': 386, 'kupang': 821, 'focus': 476, 'form': 479, 'paket': 1089, 'desember': 333, 'mebagikan': 941, 'habibah': 527, 'notebook': 1041, 'acer': 12, 'sm': 1455, 'kuasa': 812, 'hamper': 533, 'penelitan': 1123, 'abd': 3, 'hakam': 531, 'positioning': 1186, 'sunsilk': 1523, 'clean': 277, 'fresh': 486, 'santri': 1361, 'putri': 1261, 'pondok': 1178, 'pesantren': 1159, 'al': 56, 'hikam': 560, 'ciri': 274, 'dilatarbelakangi': 353, 'transaksi': 1648, 'menang': 949, 'situs': 1449, 'www': 1745, 'rumahmadani': 1340, 'acak': 10, 'chatting': 264, 'paradigma': 1099, 'selenggara': 1394, 'perintah': 1146, 'otonomi': 1077, 'undang': 1681, 'nomor': 1037, 'jabar': 664, 'indikasi': 604, 'gagal': 490, 'giat': 511, 'rencana': 1301, 'rkpd': 1330, 'kaji': 697, 'relevan': 1298, 'eselon': 432, 'iii': 584, 'kausalitas': 719, 'package': 1084, 'science': 1373, 'barat': 173, 'suka': 1514, 'lambat': 840, 'ramah': 1271, 'pulang': 1246, 'sub': 1508, 'alam': 57, 'status': 1490, 'kawin': 720, 'tabel': 1550, 'persentase': 1153, 'moderat': 992, 'bahwasannya': 155, 'diteiliti': 365, 'barokah': 174, 'prambon': 1196, 'gnakan': 517, 'kepemipinan': 737, 'kharismatik': 749, 'transaksional': 1649, 'tranforsional': 1647, 'satpam': 1371, 'marina': 926, 'sri': 1477, 'harta': 543, 'table': 1551, 'nila': 1032, 'stimulant': 1492, 'transformasional': 1650, 'unit': 1684, 'karismatik': 710, 'wiwik': 1742, 'sriwahyuni': 1478, 'laba': 832, 'sudarsono': 1512, 'ghani': 509, 'bulan': 233, 'berdasarkasn': 200, 'rotasi': 1337, 'jajar': 667, 'skpd': 1453, 'tugas': 1656, 'fungsi': 489, 'adapun': 20, 'sekunder': 1390, 'standar': 1481, 'formasi': 480, 'objektifitas': 1055, 'variabeldilakukan': 1708, 'analisiskualitatif': 82, 'asumsiklasik': 130, 'regersi': 1292, 'bahwasecara': 156, 'stimultan': 1493, 'obyektifitas': 1058, 'tri': 1651, 'aji': 38, 'circle': 273, 'taman': 1558, 'apsari': 109, 'acu': 17, 'evaluasi': 436, 'ana': 75, 'agustini': 33, 'dewi': 345, 'akuisisi': 51, 'melakuukan': 944, 'jurus': 691, 'akuisisimelakukan': 52, 'alih': 62, 'assetperusahaan': 124, 'investmen': 650, 'lima': 872, 'samples': 1355, 'suhardianto': 1513, 'karakteristik': 708, 'wildan': 1733, 'jalin': 669, 'tiap': 1619, 'maksimal': 909, 'eksplanatif': 409, 'ajar': 37, 'usia': 1698, 'ttabel': 1654, 'febrianto': 457, 'rizal': 1329, 'ii': 583, 'bersih': 204, 'tato': 1574, 'hutang': 577, 'simpel': 1436, 'wajib': 1719, 'jangka': 673, 'pendek': 1122, 'an': 74, 'characteristics': 263, 'usage': 1692, 'users': 1697, 'consumers': 288, 'syaiful': 1542, 'anwar': 103, 'selamat': 1392, 'marianal': 925, 'indo': 608, 'prima': 1208, 'kuswinarmo': 829, 'akirom': 42, 'kompetisi': 771, 'marinal': 927, 'credit': 295, 'npl': 1043, 'pd': 1111, 'bpr': 225, 'dikatagorikan': 352, 'syarat': 1544, 'performing': 1141, 'loan': 881, 'profesionalisme': 1222, 'aksesibilitas': 43, 'fleksibilitas': 473, 'reputasi': 1305, 'kredibilitas': 801, 'recovery': 1289, 'serviscape': 1409, 'pasien': 1104, 'padu': 1085, 'servisecape': 1410, 'bangkrut': 165, 'altman': 68, 'ingat': 619, 'score': 1374, 'kritis': 807, 'merk': 966, 'penggunasecara': 1128, 'sektor': 1389, 'batas': 177, 'campur': 248, 'aduk': 26, 'bawa': 182, 'sulit': 1517, 'lembur': 860, 'konflik': 781, 'pekerjaan': 1118, 'awat': 147, 'wanita': 1721, 'rs': 1338, 'syamrabu': 1543, 'dharma': 346, 'abidin': 4, 'syahkesimpulan': 1541, 'tipe': 1634, 'autoritarian': 142, 'laissez': 837, 'faire': 446, 'demokratis': 328, 'pangarengan': 1095, 'anova': 99, 'kontribusi': 787, 'autoritariansecara': 143, 'pegawaidikantor': 1116, 'fairesecara': 447, 'lai': 836, 'celebrity': 257, 'endorser': 421, 'iwan': 663, 'fals': 451, 'top': 1641, 'coffee': 279, 'sumur': 1522, 'pejagan': 1117, 'menngunakan': 960, 'aksidental': 45, 'erangkat': 427, 'trustworthiness': 1653, 'expertise': 441, 'attractiveness': 138, 'respect': 1310, 'similarity': 1434, 'minet': 974, 'miant': 969, 'liquid': 879, 'lq': 888, 'sumirah': 1521, 'ud': 1670, 'budi': 230, 'kramat': 800, 'tambrinmm': 1560, 'chrismardanissimm': 268, 'tekhnik': 1585, 'sederhana': 1383, 'rase': 1277, 'penjulannya': 1131, 'independent': 601, 'hipotesa': 562, 'signifikasi': 1431, 'konsep': 782, 'aida': 35, 'ink': 621, 'attention': 137, 'desire': 334, 'action': 15, 'mita': 983, 'anggun': 94, 'pratiwi': 1200, 'kosmetik': 794, 'wardah': 1725, 'muhamad': 1013, 'penelitin': 1124, 'survei': 1529, 'sosail': 1463, 'mahasiswi': 902, 'haryono': 545, 'arifin': 115, 'dealler': 319, 'dianalisa': 348, 'cara': 253, 'pasta': 1105, 'gigi': 512, 'pepsodent': 1135, 'norma': 1040, 'subyektif': 1510, 'subyekti': 1509, 'porporsional': 1182, 'agus': 32, 'supriadi': 1526, 'store': 1495, 'atmosphere': 135, 'bakmi': 158, 'gili': 514, 'exterior': 442, 'interior': 634, 'layout': 855, 'incidental': 597, 'anaisis': 76, 'penilitian': 1129, 'sgnifikan': 1414, 'tdak': 1578, 'stressor': 1503, 'achmad': 14, 'sulaiman': 1516, 'kp': 798, 'ri': 1321, 'eka': 407, 'karsa': 711, 'chairul': 262, 'anam': 85, 'bagaiman': 151, 'mnghitung': 986, 'inventesmen': 646, 'atur': 139, 'umkm': 1677, 'firda': 466, 'human': 575, 'resources': 1309, 'scorecard': 1375, 'hrsc': 571, 'perspektif': 1157, 'internal': 636, 'akurasi': 54, 'generalibiitas': 502, 'relevansi': 1299, 'praktikal': 1194, 'staf': 1480, 'kepala': 735, 'bauk': 180, 'kendati': 734, 'objektif': 1054, 'patok': 1109, 'skp': 1452, 'ali': 61, 'rahbini': 1268, 'andal': 88, 'gilang': 513, 'khasogi': 751, 'cerelia': 260, 'wildans': 1734, 'tulis': 1658, 'aksesoris': 44, 'stationary': 1485, 'aththaariq': 133, 'moch': 988, 'wispandono': 1739, 'ms': 1004, 'pedagogik': 1113, 'profesional': 1221, 'sertifikasi': 1407, 'judgmental': 687, 'koefisiensi': 764, 'kepribadiandan': 738}\n",
      "Encoded Document is:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>aar</th>\n",
       "      <th>abc</th>\n",
       "      <th>abcs</th>\n",
       "      <th>abd</th>\n",
       "      <th>abidin</th>\n",
       "      <th>abnormal</th>\n",
       "      <th>abnormar</th>\n",
       "      <th>abstrak</th>\n",
       "      <th>abstraksi</th>\n",
       "      <th>abtrak</th>\n",
       "      <th>...</th>\n",
       "      <th>words</th>\n",
       "      <th>wujud</th>\n",
       "      <th>www</th>\n",
       "      <th>xl</th>\n",
       "      <th>yamaha</th>\n",
       "      <th>yoghurt</th>\n",
       "      <th>yudhistira</th>\n",
       "      <th>yustina</th>\n",
       "      <th>zte</th>\n",
       "      <th>zulkifli</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044541</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028662</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012640</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021980</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 1753 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     aar  abc abcs  abd abidin abnormal abnormar   abstrak abstraksi abtrak  \\\n",
       "1    0.0  0.0  0.0  0.0    0.0      0.0      0.0  0.044541       0.0    0.0   \n",
       "2    0.0  0.0  0.0  0.0    0.0      0.0      0.0  0.032029       0.0    0.0   \n",
       "3    0.0  0.0  0.0  0.0    0.0      0.0      0.0  0.018857       0.0    0.0   \n",
       "4    0.0  0.0  0.0  0.0    0.0      0.0      0.0  0.025459       0.0    0.0   \n",
       "5    0.0  0.0  0.0  0.0    0.0      0.0      0.0  0.028662       0.0    0.0   \n",
       "..   ...  ...  ...  ...    ...      ...      ...       ...       ...    ...   \n",
       "123  0.0  0.0  0.0  0.0    0.0      0.0      0.0  0.012640       0.0    0.0   \n",
       "124  0.0  0.0  0.0  0.0    0.0      0.0      0.0  0.028050       0.0    0.0   \n",
       "125  0.0  0.0  0.0  0.0    0.0      0.0      0.0  0.000000       0.0    0.0   \n",
       "126  0.0  0.0  0.0  0.0    0.0      0.0      0.0  0.000000       0.0    0.0   \n",
       "127  0.0  0.0  0.0  0.0    0.0      0.0      0.0  0.021980       0.0    0.0   \n",
       "\n",
       "     ... words wujud  www   xl yamaha yoghurt yudhistira yustina  zte zulkifli  \n",
       "1    ...   0.0   0.0  0.0  0.0    0.0     0.0        0.0     0.0  0.0      0.0  \n",
       "2    ...   0.0   0.0  0.0  0.0    0.0     0.0        0.0     0.0  0.0      0.0  \n",
       "3    ...   0.0   0.0  0.0  0.0    0.0     0.0        0.0     0.0  0.0      0.0  \n",
       "4    ...   0.0   0.0  0.0  0.0    0.0     0.0        0.0     0.0  0.0      0.0  \n",
       "5    ...   0.0   0.0  0.0  0.0    0.0     0.0        0.0     0.0  0.0      0.0  \n",
       "..   ...   ...   ...  ...  ...    ...     ...        ...     ...  ...      ...  \n",
       "123  ...   0.0   0.0  0.0  0.0    0.0     0.0        0.0     0.0  0.0      0.0  \n",
       "124  ...   0.0   0.0  0.0  0.0    0.0     0.0        0.0     0.0  0.0      0.0  \n",
       "125  ...   0.0   0.0  0.0  0.0    0.0     0.0        0.0     0.0  0.0      0.0  \n",
       "126  ...   0.0   0.0  0.0  0.0    0.0     0.0        0.0     0.0  0.0      0.0  \n",
       "127  ...   0.0   0.0  0.0  0.0    0.0     0.0        0.0     0.0  0.0      0.0  \n",
       "\n",
       "[127 rows x 1753 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"abstrak_akhir.csv\", usecols=[\"abstraksi_akhir\"])\n",
    "data.columns = [\"hasil-akhir\"]\n",
    "data\n",
    "\n",
    "document = data['hasil-akhir']\n",
    "a=len(document)\n",
    "\n",
    "# Create a Vectorizer Object\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "vectorizer.fit(document)\n",
    "\n",
    "# Printing the identified Unique words along with their indices\n",
    "print(\"Vocabulary: \", vectorizer.vocabulary_)\n",
    "\n",
    "# Encode the Document\n",
    "vector = vectorizer.transform(document)\n",
    "\n",
    "# Summarizing the Encoded Texts\n",
    "print(\"Encoded Document is:\")\n",
    "vector.toarray()\n",
    "\n",
    "a = vectorizer.get_feature_names()\n",
    "\n",
    "tfidf = TfidfTransformer(use_idf=True, norm='l2', smooth_idf=True)\n",
    "tf = tfidf.fit_transform(vectorizer.fit_transform(document)).toarray()\n",
    "\n",
    "dfb = pd.DataFrame(data=tf,index=list(range(1, len(tf[:,1])+1, )),columns=[a])\n",
    "dfb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2327a2",
   "metadata": {},
   "source": [
    "# LSA\n",
    "LSA adalah teknik matematika/statistika untuk mengekstraksi dan menyimpulkan hubungan kontekstual arti kata yang diaplikasikan pada bagian teks yang dibutuhkan. LSA bisa digunakan untuk menilai esai dengan mengkonversikan esai menjadi matriks-matriks yang diberi nilai pada masing-masing term untuk dicari kesamaan dengan term referensi. LSA pada dasarnya adalah dekomposisi nilai tunggal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b820443",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "lsa_model = TruncatedSVD(n_components=10, algorithm='randomized', n_iter=10, random_state=42)\n",
    "\n",
    "lsa_top=lsa_model.fit_transform(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "de804e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.29230373  0.26273673 -0.0407618  ...  0.08883671  0.17748416\n",
      "   0.13080332]\n",
      " [ 0.55408874 -0.24439974 -0.07574557 ...  0.01807907  0.01838149\n",
      "   0.06649345]\n",
      " [ 0.27635951 -0.12400553 -0.02374709 ... -0.00264652 -0.01142406\n",
      "   0.21521547]\n",
      " ...\n",
      " [ 0.2426963  -0.01497963  0.00553116 ... -0.00710184 -0.21731107\n",
      "  -0.14528226]\n",
      " [ 0.27433756  0.46668321 -0.15447698 ...  0.41435018  0.19105162\n",
      "  -0.13403867]\n",
      " [ 0.19237498  0.12244924 -0.01848398 ... -0.07774647 -0.05901344\n",
      "   0.32698492]]\n",
      "(127, 10)\n"
     ]
    }
   ],
   "source": [
    "print(lsa_top)\n",
    "print(lsa_top.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c246f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0 :\n",
      "Topic  0  :  29.23037288240089\n",
      "Topic  1  :  26.273673450243784\n",
      "Topic  2  :  -4.076180248245132\n",
      "Topic  3  :  2.828920546844968\n",
      "Topic  4  :  10.91182198222143\n",
      "Topic  5  :  0.4486726080136624\n",
      "Topic  6  :  2.76247719545605\n",
      "Topic  7  :  8.883671495423446\n",
      "Topic  8  :  17.74841601015795\n",
      "Topic  9  :  13.080331819060817\n"
     ]
    }
   ],
   "source": [
    "l=lsa_top[0]\n",
    "print(\"Document 0 :\")\n",
    "for i,topic in enumerate(l):\n",
    "  print(\"Topic \",i,\" : \",topic*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1e365b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1753)\n",
      "[[ 0.00124324  0.00113136  0.00169704 ...  0.00939831  0.0006322\n",
      "   0.00159595]\n",
      " [ 0.00109735 -0.00019753 -0.0002963  ... -0.0074623  -0.00051088\n",
      "   0.00257768]\n",
      " [ 0.01227807  0.00161162  0.00241743 ... -0.00057695 -0.00026622\n",
      "   0.01482975]\n",
      " ...\n",
      " [ 0.0142178   0.00128155  0.00192232 ... -0.00191941  0.00068871\n",
      "   0.01462865]\n",
      " [ 0.00097218  0.00015808  0.00023713 ...  0.00406642  0.00044797\n",
      "   0.00489578]\n",
      " [ 0.00231095  0.00034856  0.00052285 ...  0.00917844 -0.00308777\n",
      "   0.00355657]]\n"
     ]
    }
   ],
   "source": [
    "print(lsa_model.components_.shape) # (no_of_topics*no_of_words)\n",
    "print(lsa_model.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "397a85de",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vect' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# most important words for each topic\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m vocab \u001b[38;5;241m=\u001b[39m \u001b[43mvect\u001b[49m\u001b[38;5;241m.\u001b[39mget_feature_names()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, comp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(lsa_model\u001b[38;5;241m.\u001b[39mcomponents_):\n\u001b[0;32m      5\u001b[0m     vocab_comp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(vocab, comp)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vect' is not defined"
     ]
    }
   ],
   "source": [
    "# most important words for each topic\n",
    "vocab = vectorizer.get_feature_names()\n",
    "\n",
    "for i, comp in enumerate(lsa_model.components_):\n",
    "    vocab_comp = zip(vocab, comp)\n",
    "    sorted_words = sorted(vocab_comp, key= lambda x:x[1], reverse=True)[:10]\n",
    "    print(\"Topic \"+str(i)+\": \")\n",
    "    for t in sorted_words:\n",
    "        print(t[0],end=\" \")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae304dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
